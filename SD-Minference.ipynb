{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WZRP/sd-minference/blob/main/SD-Minference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_u3q60di584x",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title # Install Dependencies\n",
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "import time\n",
        "from subprocess import getoutput\n",
        "from IPython.utils import capture\n",
        "from google.colab import drive\n",
        "\n",
        "%store -r\n",
        "\n",
        "# root_dir\n",
        "root_dir = \"/content\"\n",
        "repo_dir = os.path.join(root_dir, \"ai-image\")\n",
        "model_dir = os.path.join(root_dir, \"model_dir\")\n",
        "vae_dir = os.path.join(root_dir, \"vae\")\n",
        "\n",
        "# repo_dir\n",
        "accelerate_config = os.path.join(repo_dir, \"accelerate_config/config.yaml\")\n",
        "tools_dir = os.path.join(repo_dir, \"tools\")\n",
        "\n",
        "for store in [\n",
        "    \"root_dir\",\n",
        "    \"repo_dir\",\n",
        "    \"model_dir\",\n",
        "    \"vae_dir\",\n",
        "    \"accelerate_config\",\n",
        "    \"tools_dir\",\n",
        "]:\n",
        "    with capture.capture_output() as cap:\n",
        "        %store {store}\n",
        "        del cap\n",
        "\n",
        "repo_url = \"https://github.com/WZRP/sd-minference\"\n",
        "bitsandytes_main_py = \"/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py\"\n",
        "branch = \"\"  # @param {type: \"string\"}\n",
        "install_xformers = True  # @param {'type':'boolean'}\n",
        "mount_drive = False  # @param {type: \"boolean\"}\n",
        "verbose = False # @param {type: \"boolean\"}\n",
        "\n",
        "def read_file(filename):\n",
        "    with open(filename, \"r\") as f:\n",
        "        contents = f.read()\n",
        "    return contents\n",
        "\n",
        "def write_file(filename, contents):\n",
        "    with open(filename, \"w\") as f:\n",
        "        f.write(contents)\n",
        "\n",
        "def clone_repo(url):\n",
        "    if not os.path.exists(repo_dir):\n",
        "        os.chdir(root_dir)\n",
        "        !git clone {url} {repo_dir}\n",
        "    else:\n",
        "        os.chdir(repo_dir)\n",
        "        !git pull origin {branch} if branch else !git pull\n",
        "\n",
        "def install_dependencies():\n",
        "    s = getoutput('nvidia-smi')\n",
        "\n",
        "    if 'T4' in s:\n",
        "        !sed -i \"s@cpu@cuda@\" library/model_util.py\n",
        "\n",
        "    !pip install torchmetrics --upgrade-strategy only-if-needed --no-deps\n",
        "    !pip install lightning-utilities --upgrade-strategy only-if-needed --no-deps\n",
        "    !pip install tokenizers --upgrade-strategy only-if-needed --no-deps\n",
        "    !pip install {'-q' if not verbose else ''} --upgrade-strategy only-if-needed --no-deps -r requirements.txt\n",
        "    !pip install {'-q' if not verbose else ''} --upgrade-strategy only-if-needed --no-deps torch torchvision torchaudio torchtext torchdata --extra-index-url https://download.pytorch.org/whl/cu118\n",
        "    if install_xformers:\n",
        "        !pip install {'-q' if not verbose else ''} --upgrade-strategy only-if-needed --no-deps xformers triton\n",
        "\n",
        "    from accelerate.utils import write_basic_config\n",
        "\n",
        "    if not os.path.exists(accelerate_config):\n",
        "        write_basic_config(save_location=accelerate_config)\n",
        "\n",
        "def remove_bitsandbytes_message(filename):\n",
        "    welcome_message = \"\"\"\n",
        "def evaluate_cuda_setup():\n",
        "    print('')\n",
        "    print('='*35 + 'BUG REPORT' + '='*35)\n",
        "    print('Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues')\n",
        "    print('For effortless bug reporting copy-paste your error into this form: https://docs.google.com/forms/d/e/1FAIpQLScPB8emS3Thkp66nvqwmjTEgxp8Y9ufuWTzFyr9kJ5AoI47dQ/viewform?usp=sf_link')\n",
        "    print('='*80)\"\"\"\n",
        "\n",
        "    new_welcome_message = \"\"\"\n",
        "def evaluate_cuda_setup():\n",
        "    import os\n",
        "    if 'BITSANDBYTES_NOWELCOME' not in os.environ or str(os.environ['BITSANDBYTES_NOWELCOME']) == '0':\n",
        "        print('')\n",
        "        print('=' * 35 + 'BUG REPORT' + '=' * 35)\n",
        "        print('Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues')\n",
        "        print('For effortless bug reporting copy-paste your error into this form: https://docs.google.com/forms/d/e/1FAIpQLScPB8emS3Thkp66nvqwmjTEgxp8Y9ufuWTzFyr9kJ5AoI47dQ/viewform?usp=sf_link')\n",
        "        print('To hide this message, set the BITSANDBYTES_NOWELCOME variable like so: export BITSANDBYTES_NOWELCOME=1')\n",
        "        print('=' * 80)\"\"\"\n",
        "\n",
        "    contents = read_file(filename)\n",
        "    new_contents = contents.replace(welcome_message, new_welcome_message)\n",
        "    write_file(filename, new_contents)\n",
        "\n",
        "def main():\n",
        "    os.chdir(root_dir)\n",
        "\n",
        "    if mount_drive:\n",
        "        if not os.path.exists(\"/content/drive\"):\n",
        "            drive.mount(\"/content/drive\")\n",
        "\n",
        "    for dir in [\n",
        "        vae_dir\n",
        "    ]:\n",
        "        os.makedirs(dir, exist_ok=True)\n",
        "\n",
        "    clone_repo(repo_url)\n",
        "\n",
        "    if branch:\n",
        "        os.chdir(repo_dir)\n",
        "        status = os.system(f\"git checkout {branch}\")\n",
        "        if status != 0:\n",
        "            raise Exception(\"Failed to checkout branch or commit\")\n",
        "\n",
        "    os.chdir(repo_dir)\n",
        "\n",
        "    !apt install aria2 {'-qq' if not verbose else ''}\n",
        "\n",
        "    install_dependencies()\n",
        "    time.sleep(3)\n",
        "\n",
        "    remove_bitsandbytes_message(bitsandytes_main_py)\n",
        "\n",
        "    os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "    os.environ[\"BITSANDBYTES_NOWELCOME\"] = \"1\"\n",
        "    os.environ[\"SAFETENSORS_FAST_GPU\"] = \"1\"\n",
        "\n",
        "    cuda_path = \"/usr/local/cuda-11.8/targets/x86_64-linux/lib/\"\n",
        "    ld_library_path = os.environ.get(\"LD_LIBRARY_PATH\", \"\")\n",
        "    os.environ[\"LD_LIBRARY_PATH\"] = f\"{ld_library_path}:{cuda_path}\"\n",
        "\n",
        "main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3LWn6GzNQ4j5",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title # Install Models & Styles\n",
        "import os\n",
        "\n",
        "%store -r\n",
        "\n",
        "os.chdir(root_dir)\n",
        "\n",
        "models = {\n",
        "    \"Anime.ckpt\": \"https://huggingface.co/OpenAppMKT/Models/resolve/main/Anime.ckpt\",\n",
        "    \"Flexible.safetensors\": \"https://huggingface.co/OpenAppMKT/Models/resolve/main/Flexible.safetensors\",\n",
        "    \"Chillout.safetensors\": \"https://huggingface.co/OpenAppMKT/Models/resolve/main/Chillout.safetensors\",\n",
        "    \"Realism.safetensors\": \"https://huggingface.co/OpenAppMKT/Models/resolve/main/Realism.safetensors\",\n",
        "    \"Pixel.safetensors\": \"https://huggingface.co/OpenAppMKT/Models/resolve/main/Pixel.safetensors\",\n",
        "}\n",
        "\n",
        "install_models = []\n",
        "\n",
        "for model_name, model_url in models.items():\n",
        "    install_models.append((model_name, model_url))\n",
        "\n",
        "def install(model_name, url):\n",
        "    base_name = os.path.basename(url)\n",
        "    !aria2c --console-log-level=error --summary-interval=10 -c -x 16 -k 1M -s 16 -d {model_dir} -o {base_name} \"{url}\"\n",
        "\n",
        "def install_model():\n",
        "    for model in install_models:\n",
        "        install(model[0], model[1])\n",
        "\n",
        "install_model()\n",
        "\n",
        "vae_dir = os.path.join(root_dir, \"vae\")\n",
        "os.makedirs(vae_dir, exist_ok=True)\n",
        "\n",
        "vae_url = \"https://huggingface.co/OpenAppMKT/Models/resolve/main/anime.vae.pt\"\n",
        "vae_name = \"anime.vae.pt\"\n",
        "\n",
        "if vae_url:\n",
        "    !aria2c --console-log-level=error --summary-interval=10 -c -x 16 -k 1M -s 16 -d {vae_dir} -o {vae_name} \"{vae_url}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2ElgQk9ADQ7",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title # Generate Images\n",
        "%store -r\n",
        "\n",
        "v2 = False\n",
        "v_parameterization = False\n",
        "models = {\n",
        "    \"Anime\": \"/content/model_dir/Anime.ckpt\",\n",
        "    \"Fantasy\": \"/content/model_dir/Flexible.safetensors\",\n",
        "    \"Portrait\": \"/content/model_dir/Chillout.safetensors\",\n",
        "    \"Realism\": \"/content/model_dir/Realism.safetensors\",\n",
        "}\n",
        "model = \"Anime\"  # @param [\"Anime\", \"Fantasy\", \"Portrait\", \"Realism\"]\n",
        "model_directory = models.get(model)\n",
        "prompt = \"\"  # @param {type: \"string\"}\n",
        "negative = \"lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry\"  # @param {type: \"string\"}\n",
        "vae = \"/content/vae/anime.vae.pt\"\n",
        "outdir = \"/content/output_dir\"\n",
        "scale = 7  # param {type: \"slider\", min: 1, max: 40}\n",
        "sampler = \"k_dpm_2\"\n",
        "steps = 30  # param {type: \"slider\", min: 1, max: 100}\n",
        "precision = \"fp16\"\n",
        "width = \"512\" #@param [\"512\", \"768\", \"1024\"] {allow-input: false}\n",
        "height = \"768\" #@param [\"512\", \"768\", \"1024\"] {allow-input: false}\n",
        "style = \"None\" #@param [\"None\", \"Pixel\"] {allow-input: false}\n",
        "pixel_style = \"/content/model_dir/Pixel.safetensors\"\n",
        "images_per_prompt = 1\n",
        "batch_size = 1\n",
        "clip_skip = 2\n",
        "seed = -1\n",
        "\n",
        "final_prompt = f\"{prompt} --n {negative}\"\n",
        "\n",
        "config = {\n",
        "    \"v2\": v2,\n",
        "    \"v_parameterization\": v_parameterization,\n",
        "    \"ckpt\": model_directory,\n",
        "    \"outdir\": outdir,\n",
        "    \"xformers\": True,\n",
        "    \"vae\": vae if vae else None,\n",
        "    \"fp16\": True,\n",
        "    \"W\": width,\n",
        "    \"H\": height,\n",
        "    \"seed\": seed if seed > 0 else None,\n",
        "    \"scale\": scale,\n",
        "    \"sampler\": sampler,\n",
        "    \"steps\": steps,\n",
        "    \"max_embeddings_multiples\": 3,\n",
        "    \"batch_size\": batch_size,\n",
        "    \"images_per_prompt\": images_per_prompt,\n",
        "    \"clip_skip\": clip_skip if not v2 else None,\n",
        "    \"prompt\": final_prompt,\n",
        "    \"network_module\": \"networks.lora\" if style != \"None\" else None,\n",
        "    \"network_weight\": pixel_style if style == \"Pixel\" else None,\n",
        "    \"network_mul\": 0.8 if style == \"Pixel\" else None,\n",
        "}\n",
        "\n",
        "args = \"\"\n",
        "for k, v in config.items():\n",
        "    if isinstance(v, str):\n",
        "        args += f'--{k}=\"{v}\" '\n",
        "    if isinstance(v, bool) and v:\n",
        "        args += f\"--{k} \"\n",
        "    if isinstance(v, float) and not isinstance(v, bool):\n",
        "        args += f\"--{k}={v} \"\n",
        "    if isinstance(v, int) and not isinstance(v, bool):\n",
        "        args += f\"--{k}={v} \"\n",
        "\n",
        "final_args = f\"python gen_img_diffusers.py {args}\"\n",
        "\n",
        "os.chdir(repo_dir)\n",
        "!{final_args}\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "def upscale_image_nearest(image_path):\n",
        "    input_image = Image.open(image_path)\n",
        "    width, height = input_image.size\n",
        "    output_image = Image.new('RGB', (width*8, height*8))\n",
        "    for x in range(width*8):\n",
        "        for y in range(height*8):\n",
        "            orig_x = x // 8\n",
        "            orig_y = y // 8\n",
        "            color = input_image.getpixel((orig_x, orig_y))\n",
        "            output_image.putpixel((x, y), color)\n",
        "    return output_image\n",
        "\n",
        "def style_pixel_pro():\n",
        "    import os\n",
        "    files = os.listdir(outdir)\n",
        "    files = [file for file in files if file.lower().endswith('.png')] # filter the files by extension\n",
        "    file_paths = [os.path.join(outdir, file) for file in files]\n",
        "    file_paths.sort(key=os.path.getmtime, reverse=True)\n",
        "    latest_file_path = file_paths[0]\n",
        "    !python /content/ai-image/postprocessor/pixeldetector.py -i {latest_file_path} -o {latest_file_path} -p\n",
        "    upscaled_image = upscale_image_nearest(latest_file_path)\n",
        "    upscaled_image.save(latest_file_path)\n",
        "\n",
        "if style == \"Pixel\":\n",
        "    style_pixel_pro()"
      ]
    }
  ]
}